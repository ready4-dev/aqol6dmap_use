---
output: 
  bookdown::pdf_document2:
    includes:
      in_header: preamble.tex
    pandoc_args:
      - '--lua-filter=../Filters/scholarly-metadata.lua'
      - '--lua-filter=../Filters/author-info-blocks.lua'
    toc: no
date: "`r format(Sys.Date(),'%d %B %Y')`"
title: Apply AQoL-6D Utility Mapping Models To New Data
author:
  - name: Matthew P Hamilton
    email: matthew.hamilton@orygen.org.au
    institute: [Orygen]
    correspondence: true
  - name: Caroline X Gao
    email: caroline.gao@orygen.org.au
    institute: [Orygen, CYMH, Monash]
institute:
  - Orygen: Orygen, Parkville, Australia
  - CYMH: Centre for Youth Mental Health; University of Melbourne, Parkville, Australia
  - Monash: School of Public Health and Preventive Medicine, Monash University, Clayton, Australia
params:
  eval_1L_lgl: True
  output_type_1L_chr: PDF
  X: NULL
---

This article provides brief instructions for using the AQoL-6D mapping models distributed in the https://doi.org/10.7910/DVN/DKDIB0 dataset, which were generated by a study described in [this study](https://www.medrxiv.org/content/10.1101/2021.07.07.21260129v2.full). 

This article provides information about:

- Searching, selecting and retrieving mapping models;
- Preparing a prediction dataset for use with a selected mapping model; and
- Applying the selected mapping model to a prediction dataset to predict Quality Adjusted Life Years (QALYs).

Before reading this article, it is recommended that you familiarise yourself with the model catalogues that are also available in the https://doi.org/10.7910/DVN/DKDIB0 dataset.

Finally, to illustrate this article we have used fake data so the analysis outlined in this article should should not be used to inform decision making.

# Getting started
## Install and load required software
To run the commands in this program, you need to have the software R installed. You will also need to install the `youthu` package using the following command.

```{r eval=FALSE}
devtools::install_github("ready4-dev/youthu") 
```

You can now load the functions we will be using from the `youthu` package.

```{r message=FALSE}
library(youthu)
```

# Search, select and retrieve transfer to utility models
We can retrieve a lookup table of available mapping models using the `get_mdls_lup` function. The lookup table includes information on the names of models (which corresponds to the names in the model catalogues), the predictors used in each model and the analysis that generated each one.

```{r }
mdls_lup <- get_mdls_lup(ttu_dv_dss_tb = get_ttu_dv_dss("TTU"),
                         utility_type_chr = "AQoL-6D")
```

To review the summary information about the predictive performance of a specific model, use the relevant name from the model catalogue:

```{r}
get_dv_mdl_smrys(mdls_lup,
                 mdl_nms_chr = "PHQ9_SOFAS_1_OLS_CLL")
```

# Prepare a prediction dataset for use with a selected transfer to utility model

## Import data
You can now import and inspect the dataset you plan on using for prediction. In the below example we use fake data.

```{r }
data_tb <- make_fake_ds_one()
data_tb %>% head()
```
```{r dstb, eval = F, echo = F, tab.cap='Illustrative example of a prediction dataset', tab.id = 'dstb', results="asis"}
data_tb %>% 
  head() %>%
  ready4show::print_table(output_type_1L_chr = params$output_type_1L_chr,
                          caption_1L_chr = knitr::opts_current$get("tab.cap"),
                          mkdn_tbl_ref_1L_chr = paste0("tab:",knitr::opts_current$get("tab.id")),
                          add_to_row_ls = NULL) 
```

### Confirm dataset can be used as a prediction dataset
The prediction dataset must contain variables that correspond to all the predictors of the model you intend to apply. The allowable range and required class of each predictor variable are described in the `min_val_dbl`,	`max_val_dbl` and	`class_chr` columns of the model predictors lookup table, which can be accessed with a call to the `get_predictors_lup` function.

```{r}
predictors_lup <- get_predictors_lup(mdls_lup = mdls_lup,
                                     mdl_nm_1L_chr = "PHQ9_SOFAS_1_OLS_CLL")
predictors_lup
```

```{r predluptb, eval = F, echo = F, tab.cap='Model predictors lookup table', tab.id = 'predluptb', results="asis"}
predictors_lup %>% 
  ready4show::print_table(output_type_1L_chr = params$output_type_1L_chr,
                          caption_1L_chr = knitr::opts_current$get("tab.cap"),
                          mkdn_tbl_ref_1L_chr = paste0("tab:",knitr::opts_current$get("tab.id")),
                          add_to_row_ls = NULL) 
```

The prediction dataset must also include both a unique client identifier variable and a measurement time-point identifier variable (which must be a `factor`{.R} with two levels). The dataset also needs to be in long format (ie where measures at different time-points for the same individual are stacked on top of each other in separate rows). We can confirm these conditions hold by creating a dataset metadata object using the `make_predn_metadata_ls` function. In creating the metadata object, the function checks that the dataset can be used in conjunction with the model specified at the `mdl_nm_1L_chr` argument. If the prediction dataset uses different variable names for the predictors to those specified in the `predictors_lup`{.R} lookup table, a named vector detailing the correspondence between the two sets of variable names needs to be passed to the `predr_vars_nms_chr` argument. Finally, if you wish to specify a preferred variable name to use for the predicted utility values when applying the model, you can do this by passing this name to the `utl_var_nm_1L_chr` argument.

```{r}
predn_ds_ls <- make_predn_metadata_ls(data_tb,
                                      id_var_nm_1L_chr = "UID",
                                      msrmnt_date_var_nm_1L_chr = "Date",
                                      predr_vars_nms_chr = c(PHQ9 = "PHQ_total",
                                                             SOFAS = "SOFAS_total"),
                                      round_var_nm_1L_chr = "Timepoint",
                                      round_bl_val_1L_chr = "Baseline",
                                      utl_var_nm_1L_chr = "AQoL6D_HU",
                                      mdls_lup = mdls_lup,
                                      mdl_nm_1L_chr = "PHQ9_SOFAS_1_OLS_CLL")
```


# Apply the selected transfer to utility model to a prediction dataset to predict Quality Adjusted Life Years (QALYs)

## Predict health utility at baseline and follow-up timepoints
To generate utility predictions we use the `add_utl_predn`{.R} function. The function needs to be supplied with the prediction dataset (the value passed to argument `data_tb`) and the validated prediction metadata object we created in the previous step. 

```{r }
data_tb <- add_utl_predn(data_tb,
                         predn_ds_ls = predn_ds_ls)
data_tb %>% 
  head()
```

By default the `add_utl_predn`{.R} function samples model parameter values based on a table of model coefficients when making predictions and constrains predictions to an allowed range. You can override these defaults by adding additional arguments `new_data_is_1L_chr = "Predicted"` (which uses mean parameter values), `force_min_max_1L_lgl = F` (removes range constraint) and (if the source dataset makes available downloadable model objects) `make_from_tbl_1L_lgl = F`. These settings will produce different predictions. It is strongly recommended that you consult the model catalogue (see above) to understand how such decisions may affect the validity of the predicted values that will be generated.


```{r updtb, eval = F, echo = F, tab.cap='Prediction dataset with predicted utilities', tab.id = 'updtb', results="asis"}
data_tb %>% 
  head() %>%
  ready4show::print_table(output_type_1L_chr = params$output_type_1L_chr,
                          caption_1L_chr = knitr::opts_current$get("tab.cap"),
                          mkdn_tbl_ref_1L_chr = paste0("tab:",knitr::opts_current$get("tab.id")),
                          add_to_row_ls = NULL) 
```

Our health utility predictions are now available for use and are summarised below.

```{r }
summary(data_tb$AQoL6D_HU)
```

## Calculate QALYs
The last step is to calculate Quality Adjusted Life Years, using a method assuming a linear rate of change between timepoints.

```{r}
data_tb <- data_tb %>% add_qalys_to_ds(predn_ds_ls = predn_ds_ls,
                                       include_predrs_1L_lgl = F,
                                       reshape_1L_lgl = F)
data_tb[c(1:6,9)] %>% 
  head() 
```

```{r qalytb, eval = F, echo = F, tab.cap='Prediction dataset with QALYs', tab.id = 'qalytb', results="asis"}
data_tb %>% 
  head() %>%
  ready4show::print_table(output_type_1L_chr = params$output_type_1L_chr,
                          caption_1L_chr = knitr::opts_current$get("tab.cap"),
                          mkdn_tbl_ref_1L_chr = paste0("tab:",knitr::opts_current$get("tab.id")),
    add_to_row_ls = NULL) 
```